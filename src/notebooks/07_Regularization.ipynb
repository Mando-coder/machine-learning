{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/regularization.png\" alt=\"drawing\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Regularization**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Definition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import Ridge, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, SCORERS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_evaluation(y_test, y_test_predictions):\n",
    "    MAE = mean_absolute_error(y_test, y_test_predictions)\n",
    "    RMSE = np.sqrt(mean_squared_error(y_test, y_test_predictions))\n",
    "    print(f'MAE = {round(MAE, 2)}')\n",
    "    print(f'RMSE = {round(RMSE, 2)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the advertising data and define the features $X$ and response $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advertising = pd.read_csv('data/Advertising.csv')\n",
    "X = advertising.drop('sales', axis=\"columns\")\n",
    "y = advertising['sales']\n",
    "advertising.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup a Polynomial Regression model and define the test & training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data shape: (200, 19)\n",
      "Train data shape: (140, 19)\n"
     ]
    }
   ],
   "source": [
    "polynomial_converter = PolynomialFeatures(degree=3, include_bias=False)\n",
    "poly_features = polynomial_converter.fit_transform(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.3, random_state=101)\n",
    "\n",
    "print(f\"Raw data shape: {poly_features.shape}\")\n",
    "print(f\"Train data shape: {X_train.shape}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup a <code>StandardScaler</code> object from the  <code>SciKitLearn</code> library and scale the train and test data. The scaler should be fitted only with the train data so that there is no data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.49300171, -0.33994238,  1.61586707,  0.28407363, -0.02568776,\n",
       "        1.49677566, -0.59023161,  0.41659155,  1.6137853 ,  0.08057172,\n",
       "       -0.05392229,  1.01524393, -0.36986163,  0.52457967,  1.48737034,\n",
       "       -0.66096022, -0.16360242,  0.54694754,  1.37075536])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Regularization - Ridge Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the scikit learn documentation for the <code>Ridge</code> class, the minimization function is in the form of \n",
    "\n",
    "$||y - Xw||^2 + \\alpha ||w||^2$\n",
    "\n",
    "Where \n",
    "\n",
    "$y$ = response\n",
    "\n",
    "$X$ = feature data\n",
    "\n",
    "$w$ = estimation coefficient\n",
    "\n",
    "$\\alpha$ = tuning parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 0.58\n",
      "RMSE = 0.89\n"
     ]
    }
   ],
   "source": [
    "ridge_model = Ridge(alpha=10)\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_test_predictions_ridge = ridge_model.predict(X_test_scaled)\n",
    "error_evaluation(y_test, y_test_predictions_ridge)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beforehand we do not know wnich value of $\\alpha$ to use, fortunately there is a seperate <code>RidgeCV</code> class which incorporates cross-validation for various $\\alpha$ values into the model. \n",
    "\n",
    "By default <code>alpha = (0.1, 1.0, 10.0)</code> and <code> cv = None </code>. The parameter <code>cv</code> determines the number of K-Folds to use in the cross validation, if left at <code>None</code>, then the leave-one-out method will be used (caution this may be computationally expensive)\n",
    "\n",
    "If the leave-one-out method is used, then part of the training data set is not used, but used as a validation data set.\n",
    "\n",
    "The way the best $\\alpha$ value is chosen is based on a scoring metric, a list of them can be found using <code>SCORERS.keys()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.1 \n",
      "\n",
      "MAE = 0.43\n",
      "RMSE = 0.62\n"
     ]
    }
   ],
   "source": [
    "ridge_cv_model = RidgeCV(alphas=(0.1, 1.0, 10.0), scoring='neg_mean_absolute_error')\n",
    "ridge_cv_model.fit(X_train_scaled, y_train)\n",
    "print(f\"Best alpha: {round(ridge_cv_model.alpha_,2)} \\n\")  \n",
    "\n",
    "y_test_predictions_ridge_cv = ridge_cv_model.predict(X_test_scaled)\n",
    "error_evaluation(y_test, y_test_predictions_ridge_cv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Regularization - LASSO Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the scikit learn documentation for the <code>Lasso</code> class, the minimization function is in the form of \n",
    "\n",
    "$\\frac{1}{(2  n_{samples})} ||y - Xw||^2 + \\alpha ||w||$\n",
    "\n",
    "Where \n",
    "\n",
    "$n_{samples}$ = number of rows in the data\n",
    "\n",
    "$y$ = response\n",
    "\n",
    "$X$ = feature data\n",
    "\n",
    "$w$ = estimation coefficient\n",
    "\n",
    "$\\alpha$ = tuning parameter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to <code>RidgeCV</code>, we do not know beforehand what value of $\\alpha$ to use in the LASSO Regression. Instead of providing a <code>Tuple</code> of $\\alpha$ values to use, <code>LassoCV</code> either requires a list of alpha values, or define the range over which it should be chosen.\n",
    "\n",
    "You may get a warning that the alpha values did not converge. To solve this you can increase the number of iterations <code>max_iter</code> or increase the alpha ratio <code>eps</code> or play around with the tolerance <code> tol </code>\n",
    "\n",
    "$\\epsilon = \\frac{\\alpha_{min}}{\\alpha_{max}}$\n",
    "\n",
    "*Note: It is just a warning, it does not break the entire model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.0049 \n",
      "\n",
      "MAE = 0.43\n",
      "RMSE = 0.61\n"
     ]
    }
   ],
   "source": [
    "lasso_cv_model = LassoCV(eps=0.001, n_alphas=100, cv=5, max_iter=1_000_000)\n",
    "lasso_cv_model.fit(X_train_scaled, y_train)\n",
    "print(f\"Best alpha: {round(lasso_cv_model.alpha_, 4)} \\n\") \n",
    "\n",
    "y_test_predictions_lasso_cv = lasso_cv_model.predict(X_test_scaled)\n",
    "error_evaluation(y_test, y_test_predictions_lasso_cv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 & L2 Regularization - Elastic Net"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the scikit learn documentation for the <code>ElasticNet</code> class, the minimization function is in the form of\n",
    "\n",
    "$\\frac{1}{(2  n_{samples})} ||y - Xw||^2 + \\alpha (\\gamma) ||w|| + \\frac{1}{2} \\alpha (\\gamma - 1) ||w||^2$\n",
    "\n",
    "Where:\n",
    "\n",
    "$\\gamma$ = ratio of L1 to L2\n",
    "\n",
    "\n",
    "This works the same way as the <code>LassoCV</code> class, the value of the L1 ratio $\\gamma$ <code>l1_ratio</code> is determined through cross-validation by providing a list of possible $\\gamma$ values to test out <code>l1_ratio</code>. For this list it is recommended to use more values close to 1 (more towards lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best L1 ratio: 1.0\n",
      "Best alpha: 0.0049 \n",
      "\n",
      "MAE = 0.43\n",
      "RMSE = 0.61\n"
     ]
    }
   ],
   "source": [
    "elastic_net_cv_model = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], \n",
    "                                    eps=0.001, n_alphas=100, max_iter=1_000_000)\n",
    "elastic_net_cv_model.fit(X_train_scaled, y_train)\n",
    "print(f\"Best L1 ratio: {round(elastic_net_cv_model.l1_ratio_, 2)}\") \n",
    "print(f\"Best alpha: {round(elastic_net_cv_model.alpha_, 4)} \\n\") \n",
    "\n",
    "y_test_predictions_elastic_net_cv = lasso_cv_model.predict(X_test_scaled)\n",
    "error_evaluation(y_test, y_test_predictions_elastic_net_cv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the L1 ratio $\\gamma$ is equal to 1.0, which means the model uses only L1 (LASSO). If you compare the tuning parameter $\\alpha$ and the MAE/RMSE errors for the Elastic Net and LASSO model, they are the same. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
